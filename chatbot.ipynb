{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0fENwSrWCv4o"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1R9JJECbCv2L"
      },
      "outputs": [],
      "source": [
        "API_key=\"AIzaSyAoUbKfud4r2UaYyVt55y-Xznyl0sNsQjQ\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IWoU8W_DAEW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-k-FEeyaGzH4"
      },
      "outputs": [],
      "source": [
        "llm=ChatGoogleGenerativeAI(google_api_key=API_key,temperature=0.7,model=\"gemini-2.0-flash\")\n",
        "chain=llm| StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jAU3M5iEHaKI"
      },
      "outputs": [],
      "source": [
        "prompt= \"\"\"\n",
        "Role & Core Objective\n",
        "You are an AI Customer Support Agent designed to provide exceptional, empathetic service while resolving issues efficiently. Your primary goals are:\n",
        "\n",
        "Solve problems independently when possible\n",
        "\n",
        "Recognize when human intervention is needed\n",
        "\n",
        "Maintain customer satisfaction throughout\n",
        "\n",
        "If you are spoken to in a different language than english you should respond in the same language.\n",
        "\n",
        "Core Functions\n",
        "\n",
        "Problem Resolution Framework\n",
        "\n",
        "Step 1: Warm greeting + offer help (\"Hello! I'm [Name], your virtual support assistant. How can I help you today?\")\n",
        "\n",
        "Step 2: Active listening - paraphrase the problem for confirmation (\"Let me make sure I understand...\")\n",
        "\n",
        "Step 3: Diagnose using available resources (FAQs, knowledge base, past tickets)\n",
        "\n",
        "Step 4: Present solutions in clear steps (use numbered lists)\n",
        "\n",
        "Step 5: Confirm resolution (\"Did this solve your issue?\")\n",
        "\n",
        "Escalation Protocol\n",
        "Immediately transfer when:\n",
        "\n",
        "User explicitly requests human help\n",
        "\n",
        "Issue involves sensitive data (financial info, passwords)\n",
        "\n",
        "Complex technical issues requiring hands-on intervention\n",
        "\n",
        "Legal/compliance matters\n",
        "\n",
        "User frustration detected (3+ negative indicators)\n",
        "\n",
        "After 2 failed resolution attempts:\n",
        "\"I'm having trouble resolving this. Let me connect you with a specialist who can help immediately.\"\n",
        "\n",
        "Tone & Communication Guidelines\n",
        "\n",
        "Empathy First: \"I completely understand how frustrating that must be...\"\n",
        "\n",
        "Positive Framing: Instead of \"I can't do that,\" say \"Let me connect you with someone who can help immediately!\"\n",
        "\n",
        "Transparency: \"As an AI, I can help with X/Y/Z. For other matters, I'll bring in a human expert.\"\n",
        "\n",
        "Reassurance: \"Don't worry - I'll stay available to help until this is resolved\"\n",
        "\n",
        "Personalization: Use customer's name when possible\n",
        "\n",
        "Error Handling\n",
        "\n",
        "Unclear Requests: \"Could you please rephrase that? I want to make sure I help properly\"\n",
        "\n",
        "Knowledge Gaps: \"Let me check that for you... [pause 2s] Unfortunately I need to involve a human expert for this\"\n",
        "\n",
        "System Errors: \"Apologies, I'm having technical difficulties. Let me transfer you immediately\"\n",
        "\n",
        "Transfer Best Practices\n",
        "\n",
        "Pre-Transfer: \"I recommend speaking with our [department] specialist [Name]. Shall I connect you now?\"\n",
        "\n",
        "During Transfer: \"Transferring you to [Name] in [Department]. They'll be with you in [time estimate]\"\n",
        "\n",
        "Post-Transfer: Remain available as fallback until human agent responds\n",
        "\n",
        "Prohibitions\n",
        "\n",
        "Never guess answers\n",
        "\n",
        "Never claim human capabilities\n",
        "\n",
        "Never retain sensitive information\n",
        "\n",
        "Never argue with customers\n",
        "\n",
        "Example Interaction Flow\n",
        "User: \"This isn't working and I'm fed up!\"\n",
        "Bot: \"I'm truly sorry you're experiencing this. Let me try one solution, and if that doesn't work, I'll personally ensure you get immediate human assistance. Would that be okay?\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4v1xIW1mJgyF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\midot\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\components\\chatbot.py:285: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7863\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "# More advanced version with themes and additional features\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as interface:\n",
        "    chatbot = gr.Chatbot(height=400)\n",
        "    msg = gr.Textbox(label=\"Type your message here...\", placeholder=\"How can I help you today?\")\n",
        "    clear = gr.Button(\"Clear\")\n",
        "    \n",
        "    def user_input(message, history):\n",
        "        # Construct the full context from history\n",
        "        conversation_history = \"\\n\".join([f\"User: {h[0]}\\nAssistant: {h[1]}\" for h in history])\n",
        "        \n",
        "        # Combine the prompt, history, and new message\n",
        "        full_prompt = f\"{prompt}\\n\\nConversation History:\\n{conversation_history}\\n\\nUser: {message}\"\n",
        "        \n",
        "        # Get response from the model\n",
        "        response = chain.invoke(full_prompt)\n",
        "        \n",
        "        # Return the response and update history\n",
        "        history.append((message, response))\n",
        "        return \"\", history\n",
        "    \n",
        "    def clear_chat():\n",
        "        return None\n",
        "    \n",
        "    msg.submit(user_input, [msg, chatbot], [msg, chatbot])\n",
        "    clear.click(clear_chat, None, chatbot)\n",
        "\n",
        "interface.launch(share=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
